{
  "id": "heyKyETy1uK0xoX4",
  "meta": {
    "instanceId": "d00caf92aa0876c596905aea78b35fa33a722cc8e479133822c17064d15c2c1d",
    "templateCredsSetupCompleted": true
  },
  "name": "Optimiser l'invite",
  "tags": [
    {
      "id": "1",
      "name": "Audelalia"
    }
  ],
  "nodes": [
    {
      "id": "a58be0f5-d11d-4bec-bd8c-0c3a7325b22b",
      "name": "Lorsqu'exécuté par un autre workflow",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "position": [
        -1880,
        820
      ],
      "parameters": {
        "inputSource": "passthrough"
      },
      "typeVersion": 1.1
    },
    {
      "id": "67fe408f-e889-4eeb-9e48-f60a579c69f0",
      "name": "Agent IA",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        -1600,
        720
      ],
      "parameters": {
        "text": "={{ $json.query }}",
        "options": {
          "systemMessage": "Étant donné l'invite initiale de l'utilisateur ci-dessous, veuillez l'améliorer. Commencez par une instruction claire et précise au début. Incluez des détails spécifiques sur le contexte souhaité, le résultat, la longueur, le format et le style. Fournissez des exemples du format de sortie souhaité, si applicable. Utilisez des mots ou phrases introductifs appropriés pour guider la sortie désirée, en particulier pour la génération de code. Évitez tout langage vague ou imprécis. Plutôt que de simplement indiquer ce qu'il ne faut pas faire, donnez des indications sur ce qui doit être fait à la place. Assurez-vous que l'invite révisée reste fidèle à l'intention originale de l'utilisateur. Ne fournissez pas d'exemples de format d'invite souhaité, décrivez-le seulement. Formatez votre réponse en markdown."
        },
        "promptType": "define",
        "hasOutputParser": true
      },
      "typeVersion": 1.7
    },
    {
      "id": "8a041b31-1873-4559-96d0-35d313bffbbd",
      "name": "Telegram3",
      "type": "n8n-nodes-base.telegram",
      "onError": "continueErrorOutput",
      "position": [
        -1000,
        820
      ],
      "webhookId": "4f57022f-14cf-4c3e-b810-ae9395bf3d04",
      "parameters": {
        "text": "={{ $json.text }}",
        "chatId": "={{ $('When Executed by Another Workflow').item.json.chat_id }}",
        "additionalFields": {}
      },
      "credentials": {
        "telegramApi": {
          "id": "Vh36aBswWhClYxBM",
          "name": "Telegram account 2"
        }
      },
      "typeVersion": 1.1
    },
    {
      "id": "5161b177-0663-41c5-b778-ac14756f699c",
      "name": "Modèle de chat OpenAI",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        -1680,
        860
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o-mini"
        },
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "vIXW5likFrTSZUgz",
          "name": "Litellm-account"
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "d5f36955-74a0-4a9a-b49d-0230d6ee35bf",
      "name": "Diviser en morceaux1",
      "type": "n8n-nodes-base.code",
      "position": [
        -1180,
        820
      ],
      "parameters": {
        "jsCode": "// Get the entire output of the previous node\nlet text = $input.all() || '';\n\n// Convert the output to a string if it's not already\nif (typeof text !== 'string') {\n  text = JSON.stringify(text, null, 2); // Pretty-print JSON objects\n}\n\n// Replace multiple newlines (\\n\\n+) with a single newline (\\n)\ntext = text.replace(/\\n{2,}/g, '\\n');\n\nconst maxLength = 3072; // Telegram message character limit\nconst messages = [];\n\n// Add an optional header for the first chunk\nconst header = `# Optimized prompt\\n\\n`;\nlet currentText = header + text;\n\n// Split the output into chunks of maxLength without splitting words\nwhile (currentText.length > 0) {\n  let chunk = currentText.slice(0, maxLength);\n\n  // Ensure we don't split in the middle of a word\n  if (chunk.length === maxLength && currentText[maxLength] !== ' ') {\n    const lastSpaceIndex = chunk.lastIndexOf(' ');\n    if (lastSpaceIndex > -1) {\n      chunk = chunk.slice(0, lastSpaceIndex);\n    }\n  }\n\n  messages.push(chunk.trim()); // Trim extra whitespace for cleaner output\n  currentText = currentText.slice(chunk.length).trim(); // Remove the chunk from the remaining text\n}\n\n// Return the split messages in Markdown format\nreturn messages.map((chunk) => ({ json: { text: `\\`\\`\\`markdown\\n${chunk}\\n\\`\\`\\`` } }));\n"
      },
      "typeVersion": 2
    },
    {
      "id": "b22f3481-caeb-4506-8fe0-c7e2597772b9",
      "name": "Note adhésive",
      "type": "n8n-nodes-base.stickyNote",
      "disabled": true,
      "position": [
        -2120,
        600
      ],
      "parameters": {
        "color": 5,
        "width": 389,
        "height": 381,
        "content": "## Déclencheur\n\n- Le déclencheur peut être n'importe quoi. Pour cet exemple, le déclencheur est un appel d'un autre workflow et un message Telegram reçu.\n\n- Notez que ce workflow peut être intégré au milieu d'un autre workflow plus large."
      },
      "typeVersion": 1
    },
    {
      "id": "2bf7ebcc-2d34-4c56-b9de-c930ccb4f30f",
      "name": "Note adhésive1",
      "type": "n8n-nodes-base.stickyNote",
      "disabled": true,
      "position": [
        -1720,
        600
      ],
      "parameters": {
        "color": 6,
        "width": 489,
        "height": 381,
        "content": "# Inférence / Optimisation\n- Le déclencheur entrant est traité par un LLM avec un prompt système spécifique visant à améliorer le prompt d'entrée."
      },
      "typeVersion": 1
    },
    {
      "id": "ccc5f97e-6215-41fc-9633-f57857743282",
      "name": "Mémoire Simple",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "position": [
        -1340,
        860
      ],
      "parameters": {},
      "typeVersion": 1.3
    },
    {
      "id": "3bfb31b6-add3-4d5b-989e-df88d69e07e8",
      "name": "Note Autocollante3",
      "type": "n8n-nodes-base.stickyNote",
      "disabled": true,
      "position": [
        -1220,
        600
      ],
      "parameters": {
        "width": 349,
        "height": 381,
        "content": "# Prompt amélioré :\n\n- Envoyer en réponse\n\n- Utiliser comme entrée pour les nœuds suivants"
      },
      "typeVersion": 1
    },
    {
      "id": "a36fdc9d-d000-4120-99e8-53d49edec74a",
      "name": "Note Autocollante2",
      "type": "n8n-nodes-base.stickyNote",
      "disabled": true,
      "position": [
        -2120,
        1000
      ],
      "parameters": {
        "color": 7,
        "width": 1249,
        "height": 541,
        "content": "# Documentation du Workflow\n\n## Description :\nCe workflow est conçu pour optimiser les prompts en améliorant les entrées des utilisateurs pour plus de clarté et de spécificité grâce à l'IA. Le workflow prend un prompt fourni par l'utilisateur en entrée et utilise un modèle de Traitement du Langage Naturel (NLP) pour affiner et améliorer le prompt. Le prompt optimisé est ensuite renvoyé à l'utilisateur, prêt à être utilisé dans d'autres workflows ou processus.\n\n## Configuration :\n1. Ce workflow convient aux utilisateurs souhaitant améliorer leurs prompts pour une meilleure communication et compréhension dans leurs workflows.\n2. Le workflow utilise un Agent IA alimenté par un modèle de chat OpenAI pour améliorer les prompts des utilisateurs.\n3. Un nœud Telegram est utilisé pour renvoyer le prompt optimisé à l'utilisateur.\n4. Assurez-vous d'avoir configuré les identifiants nécessaires pour les comptes Telegram et OpenAI.\n5. Personnalisez les paramètres du workflow, tels que le modèle IA utilisé pour l'optimisation des prompts, afin de répondre à vos besoins.\n6. Activez le workflow une fois toutes les configurations effectuées pour commencer à optimiser les prompts efficacement.\n\n## Résultats attendus :\n- Les utilisateurs peuvent fournir des prompts vagues ou imprécis en entrée du workflow.\n- L'Agent IA affinera et optimisera le prompt, ajoutant clarté et détails spécifiques.\n- Le prompt optimisé sera renvoyé à l'utilisateur via Telegram pour une utilisation ultérieure dans des workflows ou processus.\n\nPour des instructions et des directives plus détaillées sur l'utilisation de ce workflow, référez-vous au guide de configuration détaillé ci-dessus."
      },
      "typeVersion": 1
    }
  ],
  "active": false,
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "05beb500-d266-45e7-8f5a-ad3a8c9a72e1",
  "connections": {
    "Agent IA": {
      "main": [
        [
          {
            "node": "Diviser en morceaux1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Mémoire Simple": {
      "ai_memory": [
        [
          {
            "node": "Agent IA",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Modèle de chat OpenAI": {
      "ai_languageModel": [
        [
          {
            "node": "Agent IA",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Diviser en morceaux1": {
      "main": [
        [
          {
            "node": "Telegram3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Lorsqu'exécuté par un autre workflow": {
      "main": [
        [
          {
            "node": "Agent IA",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}